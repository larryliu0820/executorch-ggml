// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_GGMLIR_GGML_IR_H_
#define FLATBUFFERS_GENERATED_GGMLIR_GGML_IR_H_

#include "flatbuffers/flatbuffers.h"

// Ensure the included flatbuffers.h is the same version as when this file was
// generated, otherwise it may not be compatible.
static_assert(FLATBUFFERS_VERSION_MAJOR == 24 &&
              FLATBUFFERS_VERSION_MINOR == 3 &&
              FLATBUFFERS_VERSION_REVISION == 25,
             "Non-compatible flatbuffers version included");

namespace ggml_ir {

struct Tensor;
struct TensorBuilder;

struct GgmlGraph;
struct GgmlGraphBuilder;

enum class OpCode : int32_t {
  NONE = 0,
  ADD = 1,
  MUL_MAT = 2,
  LEAKY_RELU = 3,
  CONV_2D = 4,
  CONV_2D_DW = 5,
  HARDTANH = 6,
  MEAN = 7,
  VIEW = 8,
  PERMUTE = 9,
  MUL = 10,
  NEG = 11,
  SUB = 12,
  MUL_SCALAR = 13,
  POW = 14,
  COS = 15,
  SIN = 16,
  BMM = 17,
  SIGMOID = 18,
  SOFTMAX = 19,
  LINEAR = 20,
  EMBEDDING = 21,
  SILU = 22,
  RSQRT = 30,
  UNSQUEEZE = 31,
  TRANSPOSE = 40,
  SLICE = 41,
  CAT = 42,
  REPEAT_INTERLEAVE = 43,
  INDEX = 44,
  INDEX_PUT = 45,
  REPEAT = 46,
  INDEX_MULTI = 47,
  CAST = 48,
  WHERE = 50,
  ARANGE = 51,
  FULL = 52,
  CUMSUM = 53,
  EQ = 54,
  NE = 55,
  LE = 56,
  LT = 57,
  GT = 58,
  GE = 59,
  LLAMA_ATTENTION = 60,
  BITWISE_AND = 70,
  BITWISE_OR = 71,
  LOGICAL_NOT = 72,
  ANY = 73,
  MIN = NONE,
  MAX = ANY
};

inline const OpCode (&EnumValuesOpCode())[25] {
  static const OpCode values[] = {
    OpCode::NONE,
    OpCode::ADD,
    OpCode::MUL_MAT,
    OpCode::LEAKY_RELU,
    OpCode::CONV_2D,
    OpCode::CONV_2D_DW,
    OpCode::HARDTANH,
    OpCode::MEAN,
    OpCode::VIEW,
    OpCode::PERMUTE,
    OpCode::MUL,
    OpCode::NEG,
    OpCode::LINEAR,
    OpCode::EMBEDDING,
    OpCode::SILU,
    OpCode::RSQRT,
    OpCode::UNSQUEEZE,
    OpCode::TRANSPOSE,
    OpCode::SLICE,
    OpCode::CAT,
    OpCode::REPEAT_INTERLEAVE,
    OpCode::INDEX,
    OpCode::INDEX_PUT,
    OpCode::REPEAT,
    OpCode::LLAMA_ATTENTION
  };
  return values;
}

inline const char * const *EnumNamesOpCode() {
  static const char * const names[62] = {
    "NONE",
    "ADD",
    "MUL_MAT",
    "LEAKY_RELU",
    "CONV_2D",
    "CONV_2D_DW",
    "HARDTANH",
    "MEAN",
    "VIEW",
    "PERMUTE",
    "MUL",
    "NEG",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "LINEAR",
    "EMBEDDING",
    "SILU",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "RSQRT",
    "UNSQUEEZE",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "TRANSPOSE",
    "SLICE",
    "CAT",
    "REPEAT_INTERLEAVE",
    "INDEX",
    "INDEX_PUT",
    "REPEAT",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "LLAMA_ATTENTION",
    nullptr
  };
  return names;
}

inline const char *EnumNameOpCode(OpCode e) {
  if (::flatbuffers::IsOutRange(e, OpCode::NONE, OpCode::LLAMA_ATTENTION)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesOpCode()[index];
}

enum class TensorType : int32_t {
  F32 = 0,
  F16 = 1,
  I64 = 2,
  I32 = 3,
  BOOL = 4,
  MIN = F32,
  MAX = BOOL
};

inline const TensorType (&EnumValuesTensorType())[5] {
  static const TensorType values[] = {
    TensorType::F32,
    TensorType::F16,
    TensorType::I64,
    TensorType::I32,
    TensorType::BOOL
  };
  return values;
}

inline const char * const *EnumNamesTensorType() {
  static const char * const names[6] = {
    "F32",
    "F16",
    "I64",
    "I32",
    "BOOL",
    nullptr
  };
  return names;
}

inline const char *EnumNameTensorType(TensorType e) {
  if (::flatbuffers::IsOutRange(e, TensorType::F32, TensorType::BOOL)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesTensorType()[index];
}

struct Tensor FLATBUFFERS_FINAL_CLASS : private ::flatbuffers::Table {
  typedef TensorBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_ID = 4,
    VT_TYPE = 6,
    VT_NE = 8,
    VT_OP = 10,
    VT_SRC_IDS = 12,
    VT_OP_PARAMS = 14,
    VT_DATA_KEY = 16,
    VT_IS_INPUT = 18,
    VT_IS_OUTPUT = 20,
    VT_INPUT_INDEX = 22
  };
  int32_t id() const {
    return GetField<int32_t>(VT_ID, 0);
  }
  ggml_ir::TensorType type() const {
    return static_cast<ggml_ir::TensorType>(GetField<int32_t>(VT_TYPE, 0));
  }
  const ::flatbuffers::Vector<int64_t> *ne() const {
    return GetPointer<const ::flatbuffers::Vector<int64_t> *>(VT_NE);
  }
  ggml_ir::OpCode op() const {
    return static_cast<ggml_ir::OpCode>(GetField<int32_t>(VT_OP, 0));
  }
  const ::flatbuffers::Vector<int32_t> *src_ids() const {
    return GetPointer<const ::flatbuffers::Vector<int32_t> *>(VT_SRC_IDS);
  }
  const ::flatbuffers::Vector<uint8_t> *op_params() const {
    return GetPointer<const ::flatbuffers::Vector<uint8_t> *>(VT_OP_PARAMS);
  }
  const ::flatbuffers::String *data_key() const {
    return GetPointer<const ::flatbuffers::String *>(VT_DATA_KEY);
  }
  bool is_input() const {
    return GetField<uint8_t>(VT_IS_INPUT, 0) != 0;
  }
  bool is_output() const {
    return GetField<uint8_t>(VT_IS_OUTPUT, 0) != 0;
  }
  int32_t input_index() const {
    return GetField<int32_t>(VT_INPUT_INDEX, -1);
  }
  bool Verify(::flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int32_t>(verifier, VT_ID, 4) &&
           VerifyField<int32_t>(verifier, VT_TYPE, 4) &&
           VerifyOffset(verifier, VT_NE) &&
           verifier.VerifyVector(ne()) &&
           VerifyField<int32_t>(verifier, VT_OP, 4) &&
           VerifyOffset(verifier, VT_SRC_IDS) &&
           verifier.VerifyVector(src_ids()) &&
           VerifyOffset(verifier, VT_OP_PARAMS) &&
           verifier.VerifyVector(op_params()) &&
           VerifyOffset(verifier, VT_DATA_KEY) &&
           verifier.VerifyString(data_key()) &&
           VerifyField<uint8_t>(verifier, VT_IS_INPUT, 1) &&
           VerifyField<uint8_t>(verifier, VT_IS_OUTPUT, 1) &&
           VerifyField<int32_t>(verifier, VT_INPUT_INDEX, 4) &&
           verifier.EndTable();
  }
};

struct TensorBuilder {
  typedef Tensor Table;
  ::flatbuffers::FlatBufferBuilder &fbb_;
  ::flatbuffers::uoffset_t start_;
  void add_id(int32_t id) {
    fbb_.AddElement<int32_t>(Tensor::VT_ID, id, 0);
  }
  void add_type(ggml_ir::TensorType type) {
    fbb_.AddElement<int32_t>(Tensor::VT_TYPE, static_cast<int32_t>(type), 0);
  }
  void add_ne(::flatbuffers::Offset<::flatbuffers::Vector<int64_t>> ne) {
    fbb_.AddOffset(Tensor::VT_NE, ne);
  }
  void add_op(ggml_ir::OpCode op) {
    fbb_.AddElement<int32_t>(Tensor::VT_OP, static_cast<int32_t>(op), 0);
  }
  void add_src_ids(::flatbuffers::Offset<::flatbuffers::Vector<int32_t>> src_ids) {
    fbb_.AddOffset(Tensor::VT_SRC_IDS, src_ids);
  }
  void add_op_params(::flatbuffers::Offset<::flatbuffers::Vector<uint8_t>> op_params) {
    fbb_.AddOffset(Tensor::VT_OP_PARAMS, op_params);
  }
  void add_data_key(::flatbuffers::Offset<::flatbuffers::String> data_key) {
    fbb_.AddOffset(Tensor::VT_DATA_KEY, data_key);
  }
  void add_is_input(bool is_input) {
    fbb_.AddElement<uint8_t>(Tensor::VT_IS_INPUT, static_cast<uint8_t>(is_input), 0);
  }
  void add_is_output(bool is_output) {
    fbb_.AddElement<uint8_t>(Tensor::VT_IS_OUTPUT, static_cast<uint8_t>(is_output), 0);
  }
  void add_input_index(int32_t input_index) {
    fbb_.AddElement<int32_t>(Tensor::VT_INPUT_INDEX, input_index, -1);
  }
  explicit TensorBuilder(::flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  ::flatbuffers::Offset<Tensor> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = ::flatbuffers::Offset<Tensor>(end);
    return o;
  }
};

inline ::flatbuffers::Offset<Tensor> CreateTensor(
    ::flatbuffers::FlatBufferBuilder &_fbb,
    int32_t id = 0,
    ggml_ir::TensorType type = ggml_ir::TensorType::F32,
    ::flatbuffers::Offset<::flatbuffers::Vector<int64_t>> ne = 0,
    ggml_ir::OpCode op = ggml_ir::OpCode::NONE,
    ::flatbuffers::Offset<::flatbuffers::Vector<int32_t>> src_ids = 0,
    ::flatbuffers::Offset<::flatbuffers::Vector<uint8_t>> op_params = 0,
    ::flatbuffers::Offset<::flatbuffers::String> data_key = 0,
    bool is_input = false,
    bool is_output = false,
    int32_t input_index = -1) {
  TensorBuilder builder_(_fbb);
  builder_.add_input_index(input_index);
  builder_.add_data_key(data_key);
  builder_.add_op_params(op_params);
  builder_.add_src_ids(src_ids);
  builder_.add_op(op);
  builder_.add_ne(ne);
  builder_.add_type(type);
  builder_.add_id(id);
  builder_.add_is_output(is_output);
  builder_.add_is_input(is_input);
  return builder_.Finish();
}

inline ::flatbuffers::Offset<Tensor> CreateTensorDirect(
    ::flatbuffers::FlatBufferBuilder &_fbb,
    int32_t id = 0,
    ggml_ir::TensorType type = ggml_ir::TensorType::F32,
    const std::vector<int64_t> *ne = nullptr,
    ggml_ir::OpCode op = ggml_ir::OpCode::NONE,
    const std::vector<int32_t> *src_ids = nullptr,
    const std::vector<uint8_t> *op_params = nullptr,
    const char *data_key = nullptr,
    bool is_input = false,
    bool is_output = false,
    int32_t input_index = -1) {
  auto ne__ = ne ? _fbb.CreateVector<int64_t>(*ne) : 0;
  auto src_ids__ = src_ids ? _fbb.CreateVector<int32_t>(*src_ids) : 0;
  auto op_params__ = op_params ? _fbb.CreateVector<uint8_t>(*op_params) : 0;
  auto data_key__ = data_key ? _fbb.CreateString(data_key) : 0;
  return ggml_ir::CreateTensor(
      _fbb,
      id,
      type,
      ne__,
      op,
      src_ids__,
      op_params__,
      data_key__,
      is_input,
      is_output,
      input_index);
}

struct GgmlGraph FLATBUFFERS_FINAL_CLASS : private ::flatbuffers::Table {
  typedef GgmlGraphBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_TENSORS = 4,
    VT_N_THREADS = 6
  };
  const ::flatbuffers::Vector<::flatbuffers::Offset<ggml_ir::Tensor>> *tensors() const {
    return GetPointer<const ::flatbuffers::Vector<::flatbuffers::Offset<ggml_ir::Tensor>> *>(VT_TENSORS);
  }
  int32_t n_threads() const {
    return GetField<int32_t>(VT_N_THREADS, 1);
  }
  bool Verify(::flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_TENSORS) &&
           verifier.VerifyVector(tensors()) &&
           verifier.VerifyVectorOfTables(tensors()) &&
           VerifyField<int32_t>(verifier, VT_N_THREADS, 4) &&
           verifier.EndTable();
  }
};

struct GgmlGraphBuilder {
  typedef GgmlGraph Table;
  ::flatbuffers::FlatBufferBuilder &fbb_;
  ::flatbuffers::uoffset_t start_;
  void add_tensors(::flatbuffers::Offset<::flatbuffers::Vector<::flatbuffers::Offset<ggml_ir::Tensor>>> tensors) {
    fbb_.AddOffset(GgmlGraph::VT_TENSORS, tensors);
  }
  void add_n_threads(int32_t n_threads) {
    fbb_.AddElement<int32_t>(GgmlGraph::VT_N_THREADS, n_threads, 1);
  }
  explicit GgmlGraphBuilder(::flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  ::flatbuffers::Offset<GgmlGraph> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = ::flatbuffers::Offset<GgmlGraph>(end);
    return o;
  }
};

inline ::flatbuffers::Offset<GgmlGraph> CreateGgmlGraph(
    ::flatbuffers::FlatBufferBuilder &_fbb,
    ::flatbuffers::Offset<::flatbuffers::Vector<::flatbuffers::Offset<ggml_ir::Tensor>>> tensors = 0,
    int32_t n_threads = 1) {
  GgmlGraphBuilder builder_(_fbb);
  builder_.add_n_threads(n_threads);
  builder_.add_tensors(tensors);
  return builder_.Finish();
}

inline ::flatbuffers::Offset<GgmlGraph> CreateGgmlGraphDirect(
    ::flatbuffers::FlatBufferBuilder &_fbb,
    const std::vector<::flatbuffers::Offset<ggml_ir::Tensor>> *tensors = nullptr,
    int32_t n_threads = 1) {
  auto tensors__ = tensors ? _fbb.CreateVector<::flatbuffers::Offset<ggml_ir::Tensor>>(*tensors) : 0;
  return ggml_ir::CreateGgmlGraph(
      _fbb,
      tensors__,
      n_threads);
}

inline const ggml_ir::GgmlGraph *GetGgmlGraph(const void *buf) {
  return ::flatbuffers::GetRoot<ggml_ir::GgmlGraph>(buf);
}

inline const ggml_ir::GgmlGraph *GetSizePrefixedGgmlGraph(const void *buf) {
  return ::flatbuffers::GetSizePrefixedRoot<ggml_ir::GgmlGraph>(buf);
}

inline bool VerifyGgmlGraphBuffer(
    ::flatbuffers::Verifier &verifier) {
  return verifier.VerifyBuffer<ggml_ir::GgmlGraph>(nullptr);
}

inline bool VerifySizePrefixedGgmlGraphBuffer(
    ::flatbuffers::Verifier &verifier) {
  return verifier.VerifySizePrefixedBuffer<ggml_ir::GgmlGraph>(nullptr);
}

inline void FinishGgmlGraphBuffer(
    ::flatbuffers::FlatBufferBuilder &fbb,
    ::flatbuffers::Offset<ggml_ir::GgmlGraph> root) {
  fbb.Finish(root);
}

inline void FinishSizePrefixedGgmlGraphBuffer(
    ::flatbuffers::FlatBufferBuilder &fbb,
    ::flatbuffers::Offset<ggml_ir::GgmlGraph> root) {
  fbb.FinishSizePrefixed(root);
}

}  // namespace ggml_ir

#endif  // FLATBUFFERS_GENERATED_GGMLIR_GGML_IR_H_
