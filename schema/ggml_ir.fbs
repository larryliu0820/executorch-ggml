namespace ggml_ir;

// NOTE: This IR is intentionally minimal and stable. Per-op parameters are
// encoded in `Tensor.op_params` as raw little-endian bytes.
//
// Unless otherwise stated, `src_ids` lists input tensors for the op.
// Shapes are stored in `ne` in ggml order (innermost dimension first).

enum OpCode : int32 {
    NONE = 0,

    // Basic math
    ADD = 1,             // src_ids: [a, b]
    MUL_MAT = 2,         // src_ids: [a, b]  (ggml_mul_mat)
    MUL = 10,            // src_ids: [a, b]
    NEG = 11,            // src_ids: [x]
    SUB = 12,            // src_ids: [a, b]
    MUL_SCALAR = 13,     // src_ids: [x] op_params: float32 scalar
    POW = 14,            // src_ids: [x] op_params: float32 exponent

    // Trigonometric
    COS = 15,            // src_ids: [x]
    SIN = 16,            // src_ids: [x]

    // BMM (batch matmul)
    BMM = 17,            // src_ids: [a, b]

    // Activations
    SIGMOID = 18,        // src_ids: [x]
    SOFTMAX = 19,        // src_ids: [x] op_params: int32 dim, int32 ndim

    // NN ops / activations
    LINEAR = 20,         // src_ids: [x, w, b?]  (b optional)
    EMBEDDING = 21,      // src_ids: [weight, indices]
    SILU = 22,           // src_ids: [x]
    LEAKY_RELU = 3,      // src_ids: [x]  op_params: float32 negative_slope
    HARDTANH = 6,        // src_ids: [x]  op_params: float32 min, float32 max

    // Vision (existing)
    CONV_2D = 4,
    CONV_2D_DW = 5,      // depthwise conv2d

    // Reductions / views
    MEAN = 7,            // src_ids: [x] op_params: int32 dim (only single-dim for now)
    RSQRT = 30,          // src_ids: [x]
    VIEW = 8,            // src_ids: [x]
    UNSQUEEZE = 31,      // src_ids: [x] op_params: int32 dim

    // Layout / indexing
    PERMUTE = 9,         // src_ids: [x] op_params: int32 ndim, then int32[ndim] dims
    TRANSPOSE = 40,      // src_ids: [x] op_params: int32 dim0, int32 dim1
    SLICE = 41,          // src_ids: [x] op_params: int32 dim, int64 start, int64 end, int64 step
    CAT = 42,            // src_ids: [x0, x1, ...] op_params: int32 dim
    REPEAT_INTERLEAVE = 43, // src_ids: [x] op_params: int32 dim, int32 repeats
    INDEX = 44,          // src_ids: [x, indices] op_params: int32 dim
    INDEX_PUT = 45,      // src_ids: [x, indices, values] op_params: int32 dim
    REPEAT = 46,         // src_ids: [x, like] (ggml_repeat)
    INDEX_MULTI = 47,    // src_ids: [x, idx0, idx1, ...] op_params: int32 ndims, int64 src_shape[ndims]
    CAST = 48,           // src_ids: [x] op_params: int32 target_type (TensorType enum)

    // Conditional
    WHERE = 50,          // src_ids: [cond, x, y]

    // Mask computation / comparison ops
    ARANGE = 51,         // src_ids: [] op_params: float64 start, float64 step
    FULL = 52,           // src_ids: [] op_params: float64 fill_value
    CUMSUM = 53,         // src_ids: [x] op_params: int32 dim, int32 ndim
    EQ = 54,             // src_ids: [a, (b)?] op_params: float64 scalar, int32 is_scalar
    NE = 55,             // src_ids: [a] op_params: float64 scalar, int32 is_scalar
    LE = 56,             // src_ids: [a, b]
    LT = 57,             // src_ids: [a, b]
    GT = 58,             // src_ids: [a, b]
    GE = 59,             // src_ids: [a, b]

    // Attention (fused llama.cpp/ggml path)
    LLAMA_ATTENTION = 60, // src_ids: TBD; op_params: model-specific (see runtime)

    // Bitwise / logical ops
    BITWISE_AND = 70,    // src_ids: [a, b]
    BITWISE_OR = 71,     // src_ids: [a, b]
    LOGICAL_NOT = 72,    // src_ids: [x]
    ANY = 73             // src_ids: [x] op_params: int32 dim, int32 ndim
}

enum TensorType : int32 {
    F32 = 0,
    F16 = 1,
    I64 = 2,
    I32 = 3,
    BOOL = 4,
}

table Tensor {
    id:int32;
    type:TensorType = F32;
    ne:[int64];             // shape in ggml order (innermost first), up to 4 dims
    op:OpCode = NONE;
    src_ids:[int32];        // input tensor IDs for this op
    op_params:[uint8];      // raw bytes, e.g. packed float for negative_slope

    // Constants/weights are stored in ExecuTorch's NamedDataStore/NamedDataMap.
    // Key is expected to be the *FQN* in the ExportedProgram state_dict.
    // Empty for runtime inputs.
    data_key:string;

    is_input:bool = false;
    is_output:bool = false;
    input_index:int32 = -1; // index into the runtime input list (-1 if not an input)
}

table GgmlGraph {
    tensors:[Tensor];      // in topological order
    n_threads:int32 = 1;
}

root_type GgmlGraph;
