namespace ggml_ir;

// NOTE: This IR is intentionally minimal and stable. Per-op parameters are
// encoded in `Tensor.op_params` as raw little-endian bytes.
//
// Unless otherwise stated, `src_ids` lists input tensors for the op.
// Shapes are stored in `ne` in ggml order (innermost dimension first).

enum OpCode : int32 {
    NONE = 0,

    // Basic math
    ADD = 1,             // src_ids: [a, b]
    MUL_MAT = 2,         // src_ids: [a, b]  (ggml_mul_mat)
    MUL = 10,            // src_ids: [a, b]
    NEG = 11,            // src_ids: [x]

    // NN ops / activations
    LINEAR = 20,         // src_ids: [x, w, b?]  (b optional)
    EMBEDDING = 21,      // src_ids: [weight, indices]
    SILU = 22,           // src_ids: [x]
    LEAKY_RELU = 3,      // src_ids: [x]  op_params: float32 negative_slope
    HARDTANH = 6,        // src_ids: [x]  op_params: float32 min, float32 max

    // Vision (existing)
    CONV_2D = 4,
    CONV_2D_DW = 5,      // depthwise conv2d

    // Reductions / views
    MEAN = 7,            // src_ids: [x] op_params: int32 dim (only single-dim for now)
    RSQRT = 30,          // src_ids: [x]
    VIEW = 8,            // src_ids: [x]
    UNSQUEEZE = 31,      // src_ids: [x] op_params: int32 dim

    // Layout / indexing
    PERMUTE = 9,         // src_ids: [x] op_params: int32 ndim, then int32[ndim] dims
    TRANSPOSE = 40,      // src_ids: [x] op_params: int32 dim0, int32 dim1
    SLICE = 41,          // src_ids: [x] op_params: int32 dim, int64 start, int64 end, int64 step
    CAT = 42,            // src_ids: [x0, x1, ...] op_params: int32 dim
    REPEAT_INTERLEAVE = 43, // src_ids: [x] op_params: int32 dim, int32 repeats
    INDEX = 44,          // src_ids: [x, indices] op_params: int32 dim
    INDEX_PUT = 45,      // src_ids: [x, indices, values] op_params: int32 dim
    REPEAT = 46,         // src_ids: [x, like] (ggml_repeat)
    INDEX_MULTI = 47,    // src_ids: [x, idx0, idx1, ...] op_params: int32 ndims, int64 src_shape[ndims]
    CAST = 48,           // src_ids: [x] op_params: int32 target_type (TensorType enum)

    // Attention (fused llama.cpp/ggml path)
    LLAMA_ATTENTION = 60 // src_ids: TBD; op_params: model-specific (see runtime)
}

enum TensorType : int32 {
    F32 = 0,
    F16 = 1,
    I64 = 2,
    I32 = 3,
    BOOL = 4,
}

table Tensor {
    id:int32;
    type:TensorType = F32;
    ne:[int64];             // shape in ggml order (innermost first), up to 4 dims
    op:OpCode = NONE;
    src_ids:[int32];        // input tensor IDs for this op
    op_params:[uint8];      // raw bytes, e.g. packed float for negative_slope

    // Constants/weights are stored in ExecuTorch's NamedDataStore/NamedDataMap.
    // Key is expected to be the *FQN* in the ExportedProgram state_dict.
    // Empty for runtime inputs.
    data_key:string;

    is_input:bool = false;
    is_output:bool = false;
    input_index:int32 = -1; // index into the runtime input list (-1 if not an input)
}

table GgmlGraph {
    tensors:[Tensor];      // in topological order
    n_threads:int32 = 1;
}

root_type GgmlGraph;
